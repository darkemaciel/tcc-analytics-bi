{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9fbcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pacotes\n",
    "# Bibliotecas de Modelagem de Dados e Análises\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "\n",
    "# Pacote para requisições HTTP\n",
    "import requests\n",
    "import os\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# Pacote para extrair arquivos.zip\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Manipular caminhos de arquivo e diretório de forma mais eficaz\n",
    "from pathlib import Path\n",
    "\n",
    "# Pacote para leitura e escrita de arquivos csv\n",
    "import csv\n",
    "\n",
    "# Pacote para trabalhar com dados HTML e XML\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Analises gráficas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "from datetime import datetime\n",
    "\n",
    "# SQL\n",
    "import sqlite3\n",
    "\n",
    "# Avisos\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609428de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL das páginas que contém os links para os arquivos.zip de receitas e despesas  \n",
    "url_receitas = 'https://dados.es.gov.br/dataset/receitas-municipios'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c7faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasta onde você deseja salvar os arquivos.zip\n",
    "output_folder_receitas = 'C:/Users/Darke/Documents/Especialização - Dados/Analitycs e BI/TCC/arquivos/receitas'\n",
    "\n",
    "# Certifique-se de que as pastas de saída existam\n",
    "if not os.path.exists(output_folder_receitas):\n",
    "    os.makedirs(output_folder_receitas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4783f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enviar uma solicitação HTTP para obter o conteúdo da página de receitas\n",
    "response = requests.get(url_receitas)\n",
    "if response.status_code == 200:\n",
    "    # Analisar o HTML da página\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Encontrar todos os links na página\n",
    "    links = soup.find_all('a')\n",
    "\n",
    "    # Iterar sobre os links da página de receitas\n",
    "    for link in links:\n",
    "        href = link.get('href')\n",
    "        if href and href.endswith('.zip'):\n",
    "            file_url = urljoin(url_receitas, href)\n",
    "            file_name = os.path.join(output_folder_receitas, os.path.basename(file_url))\n",
    "\n",
    "            # Baixar os arquivos de receitas.ZIP\n",
    "            with requests.get(file_url, stream=True) as file_response:\n",
    "                if file_response.status_code == 200:\n",
    "                    with open(file_name, 'wb') as file:\n",
    "                        for chunk in file_response.iter_content():\n",
    "                            file.write(chunk)\n",
    "\n",
    "                    print(f'Arquivo baixado: {file_name}')\n",
    "                else:\n",
    "                    print(f'Falha ao baixar {file_url}')\n",
    "else:\n",
    "    print(f'Falha ao acessar a página: {url_receitas}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf9ede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especifica o caminho do diretório onde os arquivos ZIP das receitas estão localizados\n",
    "caminho_arquivos_receitas = r'C:\\Users\\Darke\\Documents\\Especialização - Dados\\Analitycs e BI\\TCC\\arquivos\\receitas'\n",
    "\n",
    "# Itera sobre todos os arquivos no diretório\n",
    "for nome_arquivo_zip in os.listdir(caminho_arquivos_receitas):\n",
    "    # Constrói o caminho completo para o arquivo ZIP\n",
    "    caminho_zip = os.path.join(caminho_arquivos_receitas, nome_arquivo_zip)\n",
    "\n",
    "    # Verifica se o arquivo tem a extensão .zip e é um arquivo válido\n",
    "    if nome_arquivo_zip.endswith('.zip') and os.path.isfile(caminho_zip):\n",
    "        # Abre o arquivo ZIP e extrai seu conteúdo no mesmo diretório\n",
    "        with ZipFile(caminho_zip, 'r') as z:\n",
    "            z.extractall(path=caminho_arquivos_receitas)\n",
    "        \n",
    "        # Exibe uma mensagem indicando que os arquivos foram extraídos com sucesso\n",
    "        print(f'Arquivos extraídos em: {caminho_arquivos_receitas}')\n",
    "    else:\n",
    "        # Exibe uma mensagem se o arquivo ZIP não for válido ou não existir\n",
    "        print(f'O arquivo ZIP \"{nome_arquivo_zip}\" não é válido ou não existe no caminho especificado.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b68ed8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def encode_files(path_receitas):\n",
    "    # Informando o caminho do diretório\n",
    "    folder = Path(path_receitas)\n",
    "\n",
    "    # Iterando sobre os arquivos csv\n",
    "    for path_file in folder.glob(\"*.csv\"):\n",
    "        output = folder / (path_file.stem + \".tmp\")\n",
    "        \n",
    "        # Abre o arquivo CSV usando UTF-8. Em caso de erro, tenta novamente usando Latin-1\n",
    "        try:\n",
    "            with open(path_file, 'r', encoding=\"utf-8\") as file:\n",
    "                data = file.read()\n",
    "        except UnicodeDecodeError:\n",
    "            with open(path_file, 'r', encoding=\"latin-1\") as file:\n",
    "                data = file.read()\n",
    "                \n",
    "        # Abre o arquivo de saída temp e escreve os dados lidos do csv original\n",
    "        with open(output, 'w', encoding=\"utf-8\") as output_file:\n",
    "            output_file.write(data)\n",
    "\n",
    "        # Remove o csv original e renomeia o arquivo temporario\n",
    "        path_file.unlink()\n",
    "        output.rename(path_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path_receitas = r'C:\\Users\\Darke\\Documents\\Especialização - Dados\\Analitycs e BI\\TCC\\arquivos\\receitas'\n",
    "    encode_files(path_receitas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4801d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_csv_files(path_receitas):\n",
    "    folder = Path(path_receitas)\n",
    "    output_file_path = folder / \"receitas_unificadas.csv\"\n",
    "\n",
    "    # Iterando sobre cada arquivo csv\n",
    "    for path_file in folder.glob(\"*.csv\"):\n",
    "        with open(path_file, 'r', encoding='utf-8') as input_file:\n",
    "            csv_reader = csv.reader(input_file)\n",
    "            \n",
    "            # Se for o primeiro arquivo, escreva o header\n",
    "            if not output_file_path.exists():\n",
    "                header = next(csv_reader)\n",
    "                with open(output_file_path, 'w', encoding='utf-8', newline='') as output_file:\n",
    "                    csv_writer = csv.writer(output_file)\n",
    "                    csv_writer.writerow(header)\n",
    "\n",
    "            # Escrevendo as linhas remanescentes\n",
    "            with open(output_file_path, 'a', encoding='utf-8', newline='') as output_file:\n",
    "                csv_writer = csv.writer(output_file)\n",
    "                csv_writer.writerows(csv_reader)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path_receitas = r'C:\\Users\\Darke\\Documents\\Especialização - Dados\\Analitycs e BI\\TCC\\arquivos\\receitas'\n",
    "    merge_csv_files(path_receitas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5c3f8a",
   "metadata": {},
   "source": [
    "Neste ponto foi necessária a correção manual em determinadas linhas no arquivo de receitas unificado, pois havia dados na coluna \"NomeDetalhamento\" com \";\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6dc151",
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo_receita = r'C:\\Users\\Darke\\Documents\\Especialização - Dados\\Analitycs e BI\\TCC\\arquivos\\receitas\\receitas_unificadas.csv'\n",
    "dados = pd.read_csv(arquivo_receita, sep=';', encoding='utf-8')\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26391dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validando os anos no arquivo de receitas unificado\n",
    "dados[':Ano'] = pd.to_numeric(dados[':Ano'], errors='coerce')\n",
    "print(dados[':Ano'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9882336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirando os \"NaN\" da coluna Ano\n",
    "dados = dados.dropna(subset=[\":Ano\"])\n",
    "print(dados[':Ano'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c85db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a nova coluna data com lambda e datetime\n",
    "dados[\"data\"] = dados.apply(lambda row: datetime(int(row[\":Ano\"]), int(row[\"Mes\"]), 1), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a131af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somar o total de valores nulos em cada coluna\n",
    "total_nulos_por_coluna = dados.isnull().sum()\n",
    "\n",
    "# Somar o total de valores nulos em todo o DataFrame\n",
    "total_nulos_no_dataframe = dados.isnull().sum().sum()\n",
    "\n",
    "print(\"Total de nulos por coluna:\")\n",
    "print(total_nulos_por_coluna)\n",
    "\n",
    "print(\"\\nTotal de nulos no DataFrame:\")\n",
    "print(total_nulos_no_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857bb325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclui as colunas que não serão utilizadas\n",
    "dados = dados.drop([\"CodigoRubrica\", \"NomeRubrica\",\"NomeAlinea\", \"NomeSubAlinea\", \"NomeSubAlinea\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08194e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeando as colunas\n",
    "novos_nomes = {\n",
    "    ':Ano': 'ano',\n",
    "    'Mes': 'mes',\n",
    "    'CodigoUnidadeGestora': 'codigo_unidade_gestora',\n",
    "    'UnidadeGestora': 'unidade_gestora',\n",
    "    'EsferaAdministrativa': 'esfera_administrativa',\n",
    "    'ClassificacaoReceita': 'classificacao_receita',\n",
    "    'CodigoCategoria': 'codigo_categoria',\n",
    "    'NomeCategoria': 'nome_categoria',\n",
    "    'CodigoOrigem': 'codigo_origem',\n",
    "    'NomeOrigem': 'nome_origem',\n",
    "    'CodigoEspecie': 'codigo_especie',\n",
    "    'NomeEspecie': 'nome_especie',\n",
    "    'CodigoAlinea': 'codigo_alinea',\n",
    "    'CodigoSubAlinea': 'codigo_sub_alinea',\n",
    "    'NomeFonteReduzida': 'nome_fonteReduzida',\n",
    "    'CodigoDetalhamento': 'codigo_detalhamento',\n",
    "    'NomeGrupo': 'nome_grupo',\n",
    "    'NomeDetalhamento': 'nome_detalhamento',\n",
    "    'PrevisaoInicial': 'previsao_inicial',\n",
    "    'PrevisaoAtualizada': 'previsao_atualizada',\n",
    "    'Arrecadada': 'arrecadada',\n",
    "    'PrevisaoInicialFUNDEB': 'previsao_inicial_fundeb',\n",
    "    'PrevisaoAtualizadaFUNDEB': 'previsao_atualizada_fundeb',\n",
    "    'ArrecadadaFUNDEB': 'arrecadada_fundeb',\n",
    "    'data': 'data_arquivo',\n",
    "    'CodigoTipoDetalhamento': 'codigo_tipo_detalhamento',\n",
    "    'NomeTipoDetalhamento': 'nome_tipo_detalhamento',\n",
    "    'CodigoGrupo': 'codigo_grupo',\n",
    "    'CodigoFonteReduzida': 'codigo_fonte_reduzida',\n",
    "    'CodigoDetalhamentoNivel1': 'codigo_detalhamento_nivel_1',\n",
    "    'NomeDetalhamentoNivel1': 'nome_detalhamento_nivel_1',\n",
    "    'CodigoDetalhamentoNivel2': 'codigo_detalhamento_nivel_2',\n",
    "    'NomeDetalhamentoNivel2': 'nome_detalhamento_nivel_2',\n",
    "    'CodigoDetalhamentoNivel3': 'codigo_detalhamento_nivel_3',\n",
    "    'NomeDetalhamentoNivel3': 'nome_detalhamento_nivel_3'\n",
    "}\n",
    "\n",
    "dados.rename(columns=novos_nomes, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60609f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incluindo novo campo de data_carga no arquivo\n",
    "data_carga = datetime.now()\n",
    "dados['data_carga'] = data_carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b30f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setando as colunas como object e int\n",
    "dados['nome_detalhamento_nivel_1'] = dados['nome_detalhamento_nivel_1'].astype('object')\n",
    "dados['ano'] = dados['ano'].astype('int64')\n",
    "dados['mes'] = dados['mes'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84dec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4e7774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva as alterações de volta ao arquivo original\n",
    "dados.to_csv(arquivo_receita, sep=';', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2129fcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Carregar o arquivo unificado de receitas para o DataFrame do pandas\n",
    "csv_file_path = r'C:\\Users\\Darke\\Documents\\Especialização - Dados\\Analitycs e BI\\TCC\\arquivos\\receitas\\receitas_unificadas.csv'\n",
    "df = pd.read_csv(csv_file_path, sep=';')\n",
    "\n",
    "# Especificar o caminho para salvar o arquivo Parquet\n",
    "parquet_file_path = r'C:\\Users\\Darke\\Documents\\Especialização - Dados\\Analitycs e BI\\TCC\\arquivos\\receitas\\receitas.parquet'\n",
    "\n",
    "# Salvar o DataFrame como um arquivo Parquet\n",
    "df.to_parquet(parquet_file_path, index=False)\n",
    "\n",
    "print(f'O arquivo CSV foi convertido com sucesso para Parquet em: {parquet_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0f2ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validando o parquet arquivo convertido\n",
    "arquivo_receita = r'C:\\Users\\Darke\\Documents\\Especialização - Dados\\Analitycs e BI\\TCC\\arquivos\\receitas\\receitas.parquet'\n",
    "dados = pd.read_parquet(arquivo_receita)\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13a0b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
